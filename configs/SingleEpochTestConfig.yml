experiment_name: "SingleEpochTest"
seed: 42

model:
  architecture: "tcn"
  params:
    input_size: 40  # MFCC features
    output_size: 1  # EDA signal output
    num_blocks: 2   # Very small number of blocks for quick testing
    num_channels: 16  # Small channel size for quick testing
    kernel_size: 3
    dropout: 0.1    # Lower dropout for a smaller model

optimizer:
  name: "adamw"
  learning_rate: 0.0002
  weight_decay: 0.001
  beta1: 0.9
  beta2: 0.999
  momentum: 0.0
  warmup_steps: 0    # No warmup needed for single epoch
  warmup_ratio: 0.0
  scheduler: "constant"  # No need for complex scheduler in single epoch
  gradient_clip_val: 1.0

data:
  train_datasets:
    - pmemo2019
    - hku956
  val_datasets:
    - pmemo2019
    - hku956
  test_datasets:
    - pmemo2019
    - hku956
  batch_size: 8   # Small batch size for MPS
  num_workers: 2  # Reduced for testing
  prefetch_size: 1

loss:
  name: "mse"  # Simple loss function for testing

hardware:
  device: "mps"  # Apple Silicon GPU
  precision: "fp32"  # MPS only supports fp32
  distributed: false  # MPS doesn't support distributed training
  num_gpus: 1  # MPS only supports a single GPU

metrics:
  compute_metrics: true
  train_metrics:
    - "loss"
  val_metrics:
    - "loss"
    - "mse"
    - "dtw"  # Include all metrics to test full pipeline
  val_check_interval: 1.0
  early_stopping: false  # No early stopping needed for single epoch
  early_stopping_patience: 5
  early_stopping_min_delta: 0.01

logging:
  wandb_project: "audio2eda"
  wandb_entity: null
  wandb_run_name: "SingleEpochTest_Run"
  wandb_tags: ["test", "tcn", "pmemo2019", "hku956", "mps", "single_epoch"]
  log_every_n_steps: 10  # More frequent logging for testing

checkpoint:
  save_top_k: 1
  checkpoint_dir: "checkpoints/single_epoch_test"
  monitor: "val_loss"
  mode: "min"
  save_last: true
  save_every_n_steps: 100  # More frequent checkpoints for testing
  load_from_checkpoint: null

train:
  max_epochs: 1  # Single epoch for testing
  accumulate_grad_batches: 1
